


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>tllib.translation.cyclegan.generator &mdash; Transfer Learning Library 0.0.24 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" /> -->
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 

  
  <script src="../../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
<!--      pytorch logo -->
<!--      <a class="header-logo" href="transfer.thuml.ai" aria-label="PyTorch"></a>-->

      <div class="main-menu">
        <ul>
          <!-- <li>
            <a href="">Full Survey</a>
          </li>
          <li>
            <a href="https://github.com/thuml/Awesome-Transferability-in-Deep-Learning">Paper List</a>
          </li> -->
          <li>
            <li>
              <a href="transfer.thuml.ai">Docs</a>
            </li>
            
            <li>
              <a href="https://github.com/thuml/Transfer-Learning-Library/">Github</a>
            </li>

            <li>
              <a href="https://arxiv.org/abs/2201.05867">Survey</a>
            </li>

          <li>
            <a href="https://github.com/thuml/Awesome-Transferability-in-Deep-Learning">Paper List</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Transfer Learning API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tllib/modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tllib/alignment/index.html">Feature Alignment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tllib/translation.html">Domain Translation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tllib/self_training.html">Self Training Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tllib/reweight.html">Re-weighting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tllib/normalization.html">Normalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tllib/regularization.html">Regularization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tllib/ranking.html">Ranking</a></li>
</ul>
<p class="caption"><span class="caption-text">Common API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tllib/vision/index.html">Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tllib/utils/index.html">Utilities</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../../index.html">Module code</a> &gt;</li>
        
      <li>tllib.translation.cyclegan.generator</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for tllib.translation.cyclegan.generator</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Modified from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix</span>
<span class="sd">@author: Junguang Jiang</span>
<span class="sd">@contact: JiangJunguang1123@outlook.com</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">from</span> <span class="nn">.util</span> <span class="kn">import</span> <span class="n">get_norm_layer</span><span class="p">,</span> <span class="n">init_weights</span>


<span class="k">class</span> <span class="nc">ResnetBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Define a Resnet block&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">padding_type</span><span class="p">,</span> <span class="n">norm_layer</span><span class="p">,</span> <span class="n">use_dropout</span><span class="p">,</span> <span class="n">use_bias</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize the Resnet block</span>

<span class="sd">        A resnet block is a conv block with skip connections</span>
<span class="sd">        We construct a conv block with build_conv_block function,</span>
<span class="sd">        and implement skip connections in &lt;forward&gt; function.</span>
<span class="sd">        Original Resnet paper: https://arxiv.org/pdf/1512.03385.pdf</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ResnetBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_block</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_conv_block</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">padding_type</span><span class="p">,</span> <span class="n">norm_layer</span><span class="p">,</span> <span class="n">use_dropout</span><span class="p">,</span> <span class="n">use_bias</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">build_conv_block</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">padding_type</span><span class="p">,</span> <span class="n">norm_layer</span><span class="p">,</span> <span class="n">use_dropout</span><span class="p">,</span> <span class="n">use_bias</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Construct a convolutional block.</span>

<span class="sd">        Args:</span>
<span class="sd">            dim (int): the number of channels in the conv layer.</span>
<span class="sd">            padding_type (str): the name of padding layer: reflect | replicate | zero</span>
<span class="sd">            norm_layer (torch.nn.Module): normalization layer</span>
<span class="sd">            use_dropout (bool): if use dropout layers.</span>
<span class="sd">            use_bias (bool): if the conv layer uses bias or not</span>

<span class="sd">        Returns a conv block (with a conv layer, a normalization layer, and a non-linearity layer (ReLU))</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">conv_block</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">p</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">padding_type</span> <span class="o">==</span> <span class="s1">&#39;reflect&#39;</span><span class="p">:</span>
            <span class="n">conv_block</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">ReflectionPad2d</span><span class="p">(</span><span class="mi">1</span><span class="p">)]</span>
        <span class="k">elif</span> <span class="n">padding_type</span> <span class="o">==</span> <span class="s1">&#39;replicate&#39;</span><span class="p">:</span>
            <span class="n">conv_block</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">ReplicationPad2d</span><span class="p">(</span><span class="mi">1</span><span class="p">)]</span>
        <span class="k">elif</span> <span class="n">padding_type</span> <span class="o">==</span> <span class="s1">&#39;zero&#39;</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;padding [</span><span class="si">%s</span><span class="s1">] is not implemented&#39;</span> <span class="o">%</span> <span class="n">padding_type</span><span class="p">)</span>

        <span class="n">conv_block</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">),</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">dim</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="kc">True</span><span class="p">)]</span>
        <span class="k">if</span> <span class="n">use_dropout</span><span class="p">:</span>
            <span class="n">conv_block</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)]</span>

        <span class="n">p</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">padding_type</span> <span class="o">==</span> <span class="s1">&#39;reflect&#39;</span><span class="p">:</span>
            <span class="n">conv_block</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">ReflectionPad2d</span><span class="p">(</span><span class="mi">1</span><span class="p">)]</span>
        <span class="k">elif</span> <span class="n">padding_type</span> <span class="o">==</span> <span class="s1">&#39;replicate&#39;</span><span class="p">:</span>
            <span class="n">conv_block</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">ReplicationPad2d</span><span class="p">(</span><span class="mi">1</span><span class="p">)]</span>
        <span class="k">elif</span> <span class="n">padding_type</span> <span class="o">==</span> <span class="s1">&#39;zero&#39;</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;padding [</span><span class="si">%s</span><span class="s1">] is not implemented&#39;</span> <span class="o">%</span> <span class="n">padding_type</span><span class="p">)</span>
        <span class="n">conv_block</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">),</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">dim</span><span class="p">)]</span>

        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">conv_block</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Forward function (with skip connections)&quot;&quot;&quot;</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># add skip connections</span>
        <span class="k">return</span> <span class="n">out</span>


<span class="k">class</span> <span class="nc">ResnetGenerator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Resnet-based generator that consists of Resnet blocks between a few downsampling/upsampling operations.</span>

<span class="sd">    We adapt Torch code and idea from Justin Johnson&#39;s neural style transfer project(https://github.com/jcjohnson/fast-neural-style)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_nc</span><span class="p">,</span> <span class="n">output_nc</span><span class="p">,</span> <span class="n">ngf</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">norm_layer</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">,</span> <span class="n">use_dropout</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_blocks</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">padding_type</span><span class="o">=</span><span class="s1">&#39;reflect&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Construct a Resnet-based generator</span>

<span class="sd">        Args:</span>
<span class="sd">            input_nc (int): the number of channels in input images</span>
<span class="sd">            output_nc (int): the number of channels in output images</span>
<span class="sd">            ngf (int): the number of filters in the last conv layer</span>
<span class="sd">            norm_layer (torch.nn.Module): normalization layer</span>
<span class="sd">            use_dropout (bool): if use dropout layers</span>
<span class="sd">            n_blocks (int): the number of ResNet blocks</span>
<span class="sd">            padding_type (str): the name of padding layer in conv layers: reflect | replicate | zero</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span><span class="p">(</span><span class="n">n_blocks</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ResnetGenerator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">norm_layer</span><span class="p">)</span> <span class="o">==</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">:</span>
            <span class="n">use_bias</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="o">.</span><span class="n">func</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">use_bias</span> <span class="o">=</span> <span class="n">norm_layer</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span>

        <span class="n">model</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">ReflectionPad2d</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span>
                 <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_nc</span><span class="p">,</span> <span class="n">ngf</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">),</span>
                 <span class="n">norm_layer</span><span class="p">(</span><span class="n">ngf</span><span class="p">),</span>
                 <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="kc">True</span><span class="p">)]</span>

        <span class="n">n_downsampling</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_downsampling</span><span class="p">):</span>  <span class="c1"># add downsampling layers</span>
            <span class="n">mult</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="n">i</span>
            <span class="n">model</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="n">mult</span><span class="p">,</span> <span class="n">ngf</span> <span class="o">*</span> <span class="n">mult</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">),</span>
                      <span class="n">norm_layer</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="n">mult</span> <span class="o">*</span> <span class="mi">2</span><span class="p">),</span>
                      <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="kc">True</span><span class="p">)]</span>

        <span class="n">mult</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="n">n_downsampling</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_blocks</span><span class="p">):</span>       <span class="c1"># add ResNet blocks</span>

            <span class="n">model</span> <span class="o">+=</span> <span class="p">[</span><span class="n">ResnetBlock</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="n">mult</span><span class="p">,</span> <span class="n">padding_type</span><span class="o">=</span><span class="n">padding_type</span><span class="p">,</span> <span class="n">norm_layer</span><span class="o">=</span><span class="n">norm_layer</span><span class="p">,</span> <span class="n">use_dropout</span><span class="o">=</span><span class="n">use_dropout</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">)]</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_downsampling</span><span class="p">):</span>  <span class="c1"># add upsampling layers</span>
            <span class="n">mult</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="p">(</span><span class="n">n_downsampling</span> <span class="o">-</span> <span class="n">i</span><span class="p">)</span>
            <span class="n">model</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="n">mult</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="n">mult</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span>
                                         <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                         <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                         <span class="n">bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">),</span>
                      <span class="n">norm_layer</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="n">mult</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)),</span>
                      <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="kc">True</span><span class="p">)]</span>
        <span class="n">model</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">ReflectionPad2d</span><span class="p">(</span><span class="mi">3</span><span class="p">)]</span>
        <span class="n">model</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">ngf</span><span class="p">,</span> <span class="n">output_nc</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)]</span>
        <span class="n">model</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Standard forward&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">UnetGenerator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create a Unet-based generator&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_nc</span><span class="p">,</span> <span class="n">output_nc</span><span class="p">,</span> <span class="n">num_downs</span><span class="p">,</span> <span class="n">ngf</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">norm_layer</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">,</span> <span class="n">use_dropout</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Construct a Unet generator</span>
<span class="sd">        Args:</span>
<span class="sd">            input_nc (int): the number of channels in input images</span>
<span class="sd">            output_nc (int): the number of channels in output images</span>
<span class="sd">            num_downs (int): the number of downsamplings in UNet. For example, # if |num_downs| == 7,</span>
<span class="sd">                image of size 128x128 will become of size 1x1 # at the bottleneck</span>
<span class="sd">            ngf (int): the number of filters in the last conv layer</span>
<span class="sd">            norm_layer(torch.nn.Module): normalization layer</span>

<span class="sd">        We construct the U-Net from the innermost layer to the outermost layer.</span>
<span class="sd">        It is a recursive process.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">UnetGenerator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># construct unet structure</span>
        <span class="n">unet_block</span> <span class="o">=</span> <span class="n">UnetSkipConnectionBlock</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="n">ngf</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="n">input_nc</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">submodule</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm_layer</span><span class="o">=</span><span class="n">norm_layer</span><span class="p">,</span> <span class="n">innermost</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># add the innermost layer</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_downs</span> <span class="o">-</span> <span class="mi">5</span><span class="p">):</span>          <span class="c1"># add intermediate layers with ngf * 8 filters</span>
            <span class="n">unet_block</span> <span class="o">=</span> <span class="n">UnetSkipConnectionBlock</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="n">ngf</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="n">input_nc</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">submodule</span><span class="o">=</span><span class="n">unet_block</span><span class="p">,</span> <span class="n">norm_layer</span><span class="o">=</span><span class="n">norm_layer</span><span class="p">,</span> <span class="n">use_dropout</span><span class="o">=</span><span class="n">use_dropout</span><span class="p">)</span>
        <span class="c1"># gradually reduce the number of filters from ngf * 8 to ngf</span>
        <span class="n">unet_block</span> <span class="o">=</span> <span class="n">UnetSkipConnectionBlock</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">ngf</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="n">input_nc</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">submodule</span><span class="o">=</span><span class="n">unet_block</span><span class="p">,</span> <span class="n">norm_layer</span><span class="o">=</span><span class="n">norm_layer</span><span class="p">)</span>
        <span class="n">unet_block</span> <span class="o">=</span> <span class="n">UnetSkipConnectionBlock</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">ngf</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">input_nc</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">submodule</span><span class="o">=</span><span class="n">unet_block</span><span class="p">,</span> <span class="n">norm_layer</span><span class="o">=</span><span class="n">norm_layer</span><span class="p">)</span>
        <span class="n">unet_block</span> <span class="o">=</span> <span class="n">UnetSkipConnectionBlock</span><span class="p">(</span><span class="n">ngf</span><span class="p">,</span> <span class="n">ngf</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">input_nc</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">submodule</span><span class="o">=</span><span class="n">unet_block</span><span class="p">,</span> <span class="n">norm_layer</span><span class="o">=</span><span class="n">norm_layer</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">UnetSkipConnectionBlock</span><span class="p">(</span><span class="n">output_nc</span><span class="p">,</span> <span class="n">ngf</span><span class="p">,</span> <span class="n">input_nc</span><span class="o">=</span><span class="n">input_nc</span><span class="p">,</span> <span class="n">submodule</span><span class="o">=</span><span class="n">unet_block</span><span class="p">,</span> <span class="n">outermost</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">norm_layer</span><span class="o">=</span><span class="n">norm_layer</span><span class="p">)</span>  <span class="c1"># add the outermost layer</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Standard forward&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">UnetSkipConnectionBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Defines the Unet submodule with skip connection.</span>
<span class="sd">        X -------------------identity----------------------</span>
<span class="sd">        |-- downsampling -- |submodule| -- upsampling --|</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outer_nc</span><span class="p">,</span> <span class="n">inner_nc</span><span class="p">,</span> <span class="n">input_nc</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">submodule</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outermost</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">innermost</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">norm_layer</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">,</span> <span class="n">use_dropout</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Construct a Unet submodule with skip connections.</span>

<span class="sd">        Args:</span>
<span class="sd">            outer_nc (int): the number of filters in the outer conv layer</span>
<span class="sd">            inner_nc (int): the number of filters in the inner conv layer</span>
<span class="sd">            input_nc (int): the number of channels in input images/features</span>
<span class="sd">            submodule (UnetSkipConnectionBlock): previously defined submodules</span>
<span class="sd">            outermost (bool): if this module is the outermost module</span>
<span class="sd">            innermost (bool): if this module is the innermost module</span>
<span class="sd">            norm_layer (torch.nn.Module): normalization layer</span>
<span class="sd">            use_dropout (bool): if use dropout layers.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">UnetSkipConnectionBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outermost</span> <span class="o">=</span> <span class="n">outermost</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">norm_layer</span><span class="p">)</span> <span class="o">==</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">:</span>
            <span class="n">use_bias</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="o">.</span><span class="n">func</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">use_bias</span> <span class="o">=</span> <span class="n">norm_layer</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span>
        <span class="k">if</span> <span class="n">input_nc</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">input_nc</span> <span class="o">=</span> <span class="n">outer_nc</span>
        <span class="n">downconv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_nc</span><span class="p">,</span> <span class="n">inner_nc</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                             <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">)</span>
        <span class="n">downrelu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">downnorm</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">inner_nc</span><span class="p">)</span>
        <span class="n">uprelu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">upnorm</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">outer_nc</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">outermost</span><span class="p">:</span>
            <span class="n">upconv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">inner_nc</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">outer_nc</span><span class="p">,</span>
                                        <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                        <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">down</span> <span class="o">=</span> <span class="p">[</span><span class="n">downconv</span><span class="p">]</span>
            <span class="n">up</span> <span class="o">=</span> <span class="p">[</span><span class="n">uprelu</span><span class="p">,</span> <span class="n">upconv</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()]</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">down</span> <span class="o">+</span> <span class="p">[</span><span class="n">submodule</span><span class="p">]</span> <span class="o">+</span> <span class="n">up</span>
        <span class="k">elif</span> <span class="n">innermost</span><span class="p">:</span>
            <span class="n">upconv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">inner_nc</span><span class="p">,</span> <span class="n">outer_nc</span><span class="p">,</span>
                                        <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                        <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">)</span>
            <span class="n">down</span> <span class="o">=</span> <span class="p">[</span><span class="n">downrelu</span><span class="p">,</span> <span class="n">downconv</span><span class="p">]</span>
            <span class="n">up</span> <span class="o">=</span> <span class="p">[</span><span class="n">uprelu</span><span class="p">,</span> <span class="n">upconv</span><span class="p">,</span> <span class="n">upnorm</span><span class="p">]</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">down</span> <span class="o">+</span> <span class="n">up</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">upconv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">inner_nc</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">outer_nc</span><span class="p">,</span>
                                        <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                        <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">)</span>
            <span class="n">down</span> <span class="o">=</span> <span class="p">[</span><span class="n">downrelu</span><span class="p">,</span> <span class="n">downconv</span><span class="p">,</span> <span class="n">downnorm</span><span class="p">]</span>
            <span class="n">up</span> <span class="o">=</span> <span class="p">[</span><span class="n">uprelu</span><span class="p">,</span> <span class="n">upconv</span><span class="p">,</span> <span class="n">upnorm</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">use_dropout</span><span class="p">:</span>
                <span class="n">model</span> <span class="o">=</span> <span class="n">down</span> <span class="o">+</span> <span class="p">[</span><span class="n">submodule</span><span class="p">]</span> <span class="o">+</span> <span class="n">up</span> <span class="o">+</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">model</span> <span class="o">=</span> <span class="n">down</span> <span class="o">+</span> <span class="p">[</span><span class="n">submodule</span><span class="p">]</span> <span class="o">+</span> <span class="n">up</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">outermost</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>   <span class="c1"># add skip connections</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)],</span> <span class="mi">1</span><span class="p">)</span>


<div class="viewcode-block" id="resnet_9"><a class="viewcode-back" href="../../../../tllib/translation.html#tllib.translation.cyclegan.resnet_9">[docs]</a><span class="k">def</span> <span class="nf">resnet_9</span><span class="p">(</span><span class="n">ngf</span><span class="p">,</span> <span class="n">input_nc</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">output_nc</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="s1">&#39;batch&#39;</span><span class="p">,</span> <span class="n">use_dropout</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                       <span class="n">init_type</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span><span class="p">,</span> <span class="n">init_gain</span><span class="o">=</span><span class="mf">0.02</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Resnet-based generator with 9 Resnet blocks.</span>

<span class="sd">    Args:</span>
<span class="sd">        ngf (int): the number of filters in the last conv layer</span>
<span class="sd">        input_nc (int): the number of channels in input images. Default: 3</span>
<span class="sd">        output_nc (int): the number of channels in output images. Default: 3</span>
<span class="sd">        norm (str): the type of normalization layers used in the network. Default: &#39;batch&#39;</span>
<span class="sd">        use_dropout (bool): whether use dropout. Default: False</span>
<span class="sd">        init_type (str): the name of the initialization method. Choices includes: ``normal`` |</span>
<span class="sd">            ``xavier`` | ``kaiming`` | ``orthogonal``. Default: &#39;normal&#39;</span>
<span class="sd">        init_gain (float): scaling factor for normal, xavier and orthogonal. Default: 0.02</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">norm_layer</span> <span class="o">=</span> <span class="n">get_norm_layer</span><span class="p">(</span><span class="n">norm_type</span><span class="o">=</span><span class="n">norm</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">ResnetGenerator</span><span class="p">(</span><span class="n">input_nc</span><span class="p">,</span> <span class="n">output_nc</span><span class="p">,</span> <span class="n">ngf</span><span class="p">,</span> <span class="n">norm_layer</span><span class="o">=</span><span class="n">norm_layer</span><span class="p">,</span> <span class="n">use_dropout</span><span class="o">=</span><span class="n">use_dropout</span><span class="p">,</span> <span class="n">n_blocks</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
    <span class="n">init_weights</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">init_type</span><span class="p">,</span> <span class="n">init_gain</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">net</span></div>


<div class="viewcode-block" id="resnet_6"><a class="viewcode-back" href="../../../../tllib/translation.html#tllib.translation.cyclegan.resnet_6">[docs]</a><span class="k">def</span> <span class="nf">resnet_6</span><span class="p">(</span><span class="n">ngf</span><span class="p">,</span> <span class="n">input_nc</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">output_nc</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="s1">&#39;batch&#39;</span><span class="p">,</span> <span class="n">use_dropout</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                       <span class="n">init_type</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span><span class="p">,</span> <span class="n">init_gain</span><span class="o">=</span><span class="mf">0.02</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Resnet-based generator with 6 Resnet blocks.</span>

<span class="sd">    Args:</span>
<span class="sd">        ngf (int): the number of filters in the last conv layer</span>
<span class="sd">        input_nc (int): the number of channels in input images. Default: 3</span>
<span class="sd">        output_nc (int): the number of channels in output images. Default: 3</span>
<span class="sd">        norm (str): the type of normalization layers used in the network. Default: &#39;batch&#39;</span>
<span class="sd">        use_dropout (bool): whether use dropout. Default: False</span>
<span class="sd">        init_type (str): the name of the initialization method. Choices includes: ``normal`` |</span>
<span class="sd">            ``xavier`` | ``kaiming`` | ``orthogonal``. Default: &#39;normal&#39;</span>
<span class="sd">        init_gain (float): scaling factor for normal, xavier and orthogonal. Default: 0.02</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">norm_layer</span> <span class="o">=</span> <span class="n">get_norm_layer</span><span class="p">(</span><span class="n">norm_type</span><span class="o">=</span><span class="n">norm</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">ResnetGenerator</span><span class="p">(</span><span class="n">input_nc</span><span class="p">,</span> <span class="n">output_nc</span><span class="p">,</span> <span class="n">ngf</span><span class="p">,</span> <span class="n">norm_layer</span><span class="o">=</span><span class="n">norm_layer</span><span class="p">,</span> <span class="n">use_dropout</span><span class="o">=</span><span class="n">use_dropout</span><span class="p">,</span> <span class="n">n_blocks</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
    <span class="n">init_weights</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">init_type</span><span class="p">,</span> <span class="n">init_gain</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">net</span></div>


<div class="viewcode-block" id="unet_256"><a class="viewcode-back" href="../../../../tllib/translation.html#tllib.translation.cyclegan.unet_256">[docs]</a><span class="k">def</span> <span class="nf">unet_256</span><span class="p">(</span><span class="n">ngf</span><span class="p">,</span> <span class="n">input_nc</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">output_nc</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="s1">&#39;batch&#39;</span><span class="p">,</span> <span class="n">use_dropout</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
             <span class="n">init_type</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span><span class="p">,</span> <span class="n">init_gain</span><span class="o">=</span><span class="mf">0.02</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    `U-Net &lt;https://arxiv.org/abs/1505.04597&gt;`_ generator for 256x256 input images.</span>
<span class="sd">    The size of the input image should be a multiple of 256.</span>

<span class="sd">    Args:</span>
<span class="sd">        ngf (int): the number of filters in the last conv layer</span>
<span class="sd">        input_nc (int): the number of channels in input images. Default: 3</span>
<span class="sd">        output_nc (int): the number of channels in output images. Default: 3</span>
<span class="sd">        norm (str): the type of normalization layers used in the network. Default: &#39;batch&#39;</span>
<span class="sd">        use_dropout (bool): whether use dropout. Default: False</span>
<span class="sd">        init_type (str): the name of the initialization method. Choices includes: ``normal`` |</span>
<span class="sd">            ``xavier`` | ``kaiming`` | ``orthogonal``. Default: &#39;normal&#39;</span>
<span class="sd">        init_gain (float): scaling factor for normal, xavier and orthogonal. Default: 0.02</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">norm_layer</span> <span class="o">=</span> <span class="n">get_norm_layer</span><span class="p">(</span><span class="n">norm_type</span><span class="o">=</span><span class="n">norm</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">UnetGenerator</span><span class="p">(</span><span class="n">input_nc</span><span class="p">,</span> <span class="n">output_nc</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">ngf</span><span class="p">,</span> <span class="n">norm_layer</span><span class="o">=</span><span class="n">norm_layer</span><span class="p">,</span> <span class="n">use_dropout</span><span class="o">=</span><span class="n">use_dropout</span><span class="p">)</span>
    <span class="n">init_weights</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">init_type</span><span class="p">,</span> <span class="n">init_gain</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">net</span></div>


<div class="viewcode-block" id="unet_128"><a class="viewcode-back" href="../../../../tllib/translation.html#tllib.translation.cyclegan.unet_128">[docs]</a><span class="k">def</span> <span class="nf">unet_128</span><span class="p">(</span><span class="n">ngf</span><span class="p">,</span> <span class="n">input_nc</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">output_nc</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="s1">&#39;batch&#39;</span><span class="p">,</span> <span class="n">use_dropout</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
             <span class="n">init_type</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span><span class="p">,</span> <span class="n">init_gain</span><span class="o">=</span><span class="mf">0.02</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    `U-Net &lt;https://arxiv.org/abs/1505.04597&gt;`_ generator for 128x128 input images.</span>
<span class="sd">    The size of the input image should be a multiple of 128.</span>

<span class="sd">    Args:</span>
<span class="sd">        ngf (int): the number of filters in the last conv layer</span>
<span class="sd">        input_nc (int): the number of channels in input images. Default: 3</span>
<span class="sd">        output_nc (int): the number of channels in output images. Default: 3</span>
<span class="sd">        norm (str): the type of normalization layers used in the network. Default: &#39;batch&#39;</span>
<span class="sd">        use_dropout (bool): whether use dropout. Default: False</span>
<span class="sd">        init_type (str): the name of the initialization method. Choices includes: ``normal`` |</span>
<span class="sd">            ``xavier`` | ``kaiming`` | ``orthogonal``. Default: &#39;normal&#39;</span>
<span class="sd">        init_gain (float): scaling factor for normal, xavier and orthogonal. Default: 0.02</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">norm_layer</span> <span class="o">=</span> <span class="n">get_norm_layer</span><span class="p">(</span><span class="n">norm_type</span><span class="o">=</span><span class="n">norm</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">UnetGenerator</span><span class="p">(</span><span class="n">input_nc</span><span class="p">,</span> <span class="n">output_nc</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="n">ngf</span><span class="p">,</span> <span class="n">norm_layer</span><span class="o">=</span><span class="n">norm_layer</span><span class="p">,</span> <span class="n">use_dropout</span><span class="o">=</span><span class="n">use_dropout</span><span class="p">)</span>
    <span class="n">init_weights</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">init_type</span><span class="p">,</span> <span class="n">init_gain</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">net</span></div>


<span class="k">def</span> <span class="nf">unet_32</span><span class="p">(</span><span class="n">ngf</span><span class="p">,</span> <span class="n">input_nc</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">output_nc</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="s1">&#39;batch&#39;</span><span class="p">,</span> <span class="n">use_dropout</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
             <span class="n">init_type</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span><span class="p">,</span> <span class="n">init_gain</span><span class="o">=</span><span class="mf">0.02</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    `U-Net &lt;https://arxiv.org/abs/1505.04597&gt;`_ generator for 32x32 input images</span>

<span class="sd">    Args:</span>
<span class="sd">        ngf (int): the number of filters in the last conv layer</span>
<span class="sd">        input_nc (int): the number of channels in input images. Default: 3</span>
<span class="sd">        output_nc (int): the number of channels in output images. Default: 3</span>
<span class="sd">        norm (str): the type of normalization layers used in the network. Default: &#39;batch&#39;</span>
<span class="sd">        use_dropout (bool): whether use dropout. Default: False</span>
<span class="sd">        init_type (str): the name of the initialization method. Choices includes: ``normal`` |</span>
<span class="sd">            ``xavier`` | ``kaiming`` | ``orthogonal``. Default: &#39;normal&#39;</span>
<span class="sd">        init_gain (float): scaling factor for normal, xavier and orthogonal. Default: 0.02</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">norm_layer</span> <span class="o">=</span> <span class="n">get_norm_layer</span><span class="p">(</span><span class="n">norm_type</span><span class="o">=</span><span class="n">norm</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">UnetGenerator</span><span class="p">(</span><span class="n">input_nc</span><span class="p">,</span> <span class="n">output_nc</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">ngf</span><span class="p">,</span> <span class="n">norm_layer</span><span class="o">=</span><span class="n">norm_layer</span><span class="p">,</span> <span class="n">use_dropout</span><span class="o">=</span><span class="n">use_dropout</span><span class="p">)</span>
    <span class="n">init_weights</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">init_type</span><span class="p">,</span> <span class="n">init_gain</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">net</span>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright THUML Group.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://github.com/pytorch/pytorch_sphinx_theme">PyTorch Sphinx Theme</a>.
      </div>
      <!-- <div>
        <a href="https://beian.miit.gov.cn/">ICP16023543-1</a>
      </div> -->
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
         <script src="../../../../_static/jquery.js"></script>
         <script src="../../../../_static/underscore.js"></script>
         <script src="../../../../_static/doctools.js"></script>
         <script src="../../../../_static/language_data.js"></script>
         <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
     

  

  <script type="text/javascript" src="../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(false);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <!-- <div class="col-md-4 text-center">
          <h2>Survey</h2>
          <p>Access comprehensive survey for transfer learning</p>
          <a class="with-right-arrow" href="">View Survey</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Papers</h2>
          <p>Access comprehensive paper list for transfer learning</p>
          <a class="with-right-arrow" href="https://github.com/thuml/Awesome-Transferability-in-Deep-Learning">View Paper List</a>
        </div> -->

        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive documentation for Transfer Learning Library</p>
          <a class="with-right-arrow" href="transfer.thuml.ai">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get started for Transfer Learning Library</p>
          <a class="with-right-arrow" href="http://microhhh.com/get_started/installing.html">Get Started</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Paper List</h2>
          <p>Get started for transfer learning</p>
          <a class="with-right-arrow" href="https://github.com/thuml/Awesome-Transferability-in-Deep-Learning">View Resources</a>
        </div>
      </div>
    </div>
  </div>



  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebooks Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="transfer.thuml.ai" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="http://microhhh.com/get_started/installing.html">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="transfer.thuml.ai">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/elastic/">TorchElastic</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/thuml/Transfer-Learning-Library/">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>