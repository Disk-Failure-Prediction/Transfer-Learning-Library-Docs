


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>tllib.alignment.d_adapt.modeling.meta_arch.rcnn &mdash; Transfer Learning Library 0.0.24 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../../../_static/pygments.css" type="text/css" /> -->
    <link rel="index" title="Index" href="../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../search.html" /> 

  
  <script src="../../../../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
<!--      pytorch logo -->
<!--      <a class="header-logo" href="transfer.thuml.ai" aria-label="PyTorch"></a>-->

      <div class="main-menu">
        <ul>
          <!-- <li>
            <a href="">Full Survey</a>
          </li>
          <li>
            <a href="https://github.com/thuml/Awesome-Transferability-in-Deep-Learning">Paper List</a>
          </li> -->
          <li>
            <li>
              <a href="transfer.thuml.ai">Docs</a>
            </li>
            
            <li>
              <a href="https://github.com/thuml/Transfer-Learning-Library/">Github</a>
            </li>

            <li>
              <a href="https://arxiv.org/abs/2201.05867">Survey</a>
            </li>

          <li>
            <a href="https://github.com/thuml/Awesome-Transferability-in-Deep-Learning">Paper List</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Transfer Learning API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../tllib/modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../tllib/alignment/index.html">Feature Alignment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../tllib/translation.html">Domain Translation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../tllib/self_training.html">Self Training Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../tllib/reweight.html">Re-weighting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../tllib/normalization.html">Normalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../tllib/regularization.html">Regularization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../tllib/ranking.html">Ranking</a></li>
</ul>
<p class="caption"><span class="caption-text">Common API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../tllib/vision/index.html">Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../tllib/utils/index.html">Utilities</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../../../../index.html">Module code</a> &gt;</li>
        
      <li>tllib.alignment.d_adapt.modeling.meta_arch.rcnn</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for tllib.alignment.d_adapt.modeling.meta_arch.rcnn</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">@author: Junguang Jiang</span>
<span class="sd">@contact: JiangJunguang1123@outlook.com</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Dict</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">detectron2.utils.events</span> <span class="kn">import</span> <span class="n">get_event_storage</span>
<span class="kn">from</span> <span class="nn">detectron2.structures</span> <span class="kn">import</span> <span class="n">Instances</span>
<span class="kn">from</span> <span class="nn">detectron2.data.detection_utils</span> <span class="kn">import</span> <span class="n">convert_image_to_rgb</span>
<span class="kn">from</span> <span class="nn">detectron2.modeling.postprocessing</span> <span class="kn">import</span> <span class="n">detector_postprocess</span>
<span class="kn">from</span> <span class="nn">detectron2.modeling.meta_arch.build</span> <span class="kn">import</span> <span class="n">META_ARCH_REGISTRY</span>

<span class="kn">from</span> <span class="nn">tllib.vision.models.object_detection.meta_arch</span> <span class="kn">import</span> <span class="n">TLGeneralizedRCNN</span>


<div class="viewcode-block" id="DecoupledGeneralizedRCNN"><a class="viewcode-back" href="../../../../../../tllib/alignment/domain_adversarial.html#tllib.alignment.d_adapt.modeling.meta_arch.DecoupledGeneralizedRCNN">[docs]</a><span class="nd">@META_ARCH_REGISTRY</span><span class="o">.</span><span class="n">register</span><span class="p">()</span>
<span class="k">class</span> <span class="nc">DecoupledGeneralizedRCNN</span><span class="p">(</span><span class="n">TLGeneralizedRCNN</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generalized R-CNN for Decoupled Adaptation (D-adapt).</span>
<span class="sd">    Similar to that in in Supervised Learning, DecoupledGeneralizedRCNN has the following three components:</span>
<span class="sd">    1. Per-image feature extraction (aka backbone)</span>
<span class="sd">    2. Region proposal generation</span>
<span class="sd">    3. Per-region feature extraction and prediction</span>

<span class="sd">    Different from that in Supervised Learning, DecoupledGeneralizedRCNN</span>
<span class="sd">    1. accepts unlabeled images and uses the feedbacks from adaptors as supervision during training</span>
<span class="sd">    2. generate foreground and background proposals during inference</span>

<span class="sd">    Args:</span>
<span class="sd">        backbone: a backbone module, must follow detectron2&#39;s backbone interface</span>
<span class="sd">        proposal_generator: a module that generates proposals using backbone features</span>
<span class="sd">        roi_heads: a ROI head that performs per-region computation</span>
<span class="sd">        pixel_mean, pixel_std: list or tuple with #channels element,</span>
<span class="sd">            representing the per-channel mean and std to be used to normalize</span>
<span class="sd">            the input image</span>
<span class="sd">        input_format: describe the meaning of channels of input. Needed by visualization</span>
<span class="sd">        vis_period: the period to run visualization. Set to 0 to disable.</span>
<span class="sd">        finetune (bool): whether finetune the detector or train from scratch. Default: True</span>

<span class="sd">    Inputs:</span>
<span class="sd">        - batched_inputs: a list, batched outputs of :class:`DatasetMapper`.</span>
<span class="sd">          Each item in the list contains the inputs for one image.</span>
<span class="sd">          For now, each item in the list is a dict that contains:</span>
<span class="sd">            * image: Tensor, image in (C, H, W) format.</span>
<span class="sd">            * instances (optional): groundtruth :class:`Instances`</span>
<span class="sd">            * feedbacks (optional): :class:`Instances`, feedbacks from adaptors.</span>
<span class="sd">            * &quot;height&quot;, &quot;width&quot; (int): the output resolution of the model, used in inference.</span>
<span class="sd">              See :meth:`postprocess` for details.</span>
<span class="sd">        - labeled (bool, optional): whether has ground-truth label</span>

<span class="sd">    Outputs:</span>
<span class="sd">        - outputs (during inference): A list of dict where each dict is the output for one input image.</span>
<span class="sd">          The dict contains a key &quot;instances&quot; whose value is a :class:`Instances`.</span>
<span class="sd">          The :class:`Instances` object has the following keys:</span>
<span class="sd">          &quot;pred_boxes&quot;, &quot;pred_classes&quot;, &quot;scores&quot;, &quot;pred_masks&quot;, &quot;pred_keypoints&quot;</span>
<span class="sd">        - losses (during training): A dict of different losses</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batched_inputs</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span> <span class="n">labeled</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">batched_inputs</span><span class="p">)</span>

        <span class="n">images</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess_image</span><span class="p">(</span><span class="n">batched_inputs</span><span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;instances&quot;</span> <span class="ow">in</span> <span class="n">batched_inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="n">gt_instances</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;instances&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">batched_inputs</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">gt_instances</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backbone</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">tensor</span><span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;feedbacks&quot;</span> <span class="ow">in</span> <span class="n">batched_inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="n">feedbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;feedbacks&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">batched_inputs</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">feedbacks</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">proposals</span><span class="p">,</span> <span class="n">proposal_losses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proposal_generator</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">gt_instances</span><span class="p">,</span> <span class="n">labeled</span><span class="o">=</span><span class="n">labeled</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">detector_losses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">roi_heads</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">proposals</span><span class="p">,</span> <span class="n">gt_instances</span><span class="p">,</span> <span class="n">feedbacks</span><span class="p">,</span> <span class="n">labeled</span><span class="o">=</span><span class="n">labeled</span><span class="p">)</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">losses</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">detector_losses</span><span class="p">)</span>
        <span class="n">losses</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">proposal_losses</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">vis_period</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">storage</span> <span class="o">=</span> <span class="n">get_event_storage</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">storage</span><span class="o">.</span><span class="n">iter</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">vis_period</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">visualize_training</span><span class="p">(</span><span class="n">batched_inputs</span><span class="p">,</span> <span class="n">proposals</span><span class="p">,</span> <span class="n">feedbacks</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">losses</span>

    <span class="k">def</span> <span class="nf">visualize_training</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batched_inputs</span><span class="p">,</span> <span class="n">proposals</span><span class="p">,</span> <span class="n">feedbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A function used to visualize images and proposals. It shows ground truth</span>
<span class="sd">        bounding boxes on the original image and up to 20 top-scoring predicted</span>
<span class="sd">        object proposals on the original image. Users can implement different</span>
<span class="sd">        visualization functions for different models.</span>

<span class="sd">        Args:</span>
<span class="sd">            batched_inputs (list): a list that contains input to the model.</span>
<span class="sd">            proposals (list): a list that contains predicted proposals. Both</span>
<span class="sd">                batched_inputs and proposals should have the same length.</span>
<span class="sd">            feedbacks (list): a list that contains feedbacks from adaptors. Both</span>
<span class="sd">                batched_inputs and feedbacks should have the same length.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">detectron2.utils.visualizer</span> <span class="kn">import</span> <span class="n">Visualizer</span>

        <span class="n">storage</span> <span class="o">=</span> <span class="n">get_event_storage</span><span class="p">()</span>
        <span class="n">max_vis_prop</span> <span class="o">=</span> <span class="mi">20</span>

        <span class="k">for</span> <span class="nb">input</span><span class="p">,</span> <span class="n">prop</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">batched_inputs</span><span class="p">,</span> <span class="n">proposals</span><span class="p">):</span>
            <span class="n">img</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">]</span>
            <span class="n">img</span> <span class="o">=</span> <span class="n">convert_image_to_rgb</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_format</span><span class="p">)</span>
            <span class="n">v_gt</span> <span class="o">=</span> <span class="n">Visualizer</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">v_gt</span> <span class="o">=</span> <span class="n">v_gt</span><span class="o">.</span><span class="n">overlay_instances</span><span class="p">(</span><span class="n">boxes</span><span class="o">=</span><span class="nb">input</span><span class="p">[</span><span class="s2">&quot;instances&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">gt_boxes</span><span class="p">)</span>
            <span class="n">anno_img</span> <span class="o">=</span> <span class="n">v_gt</span><span class="o">.</span><span class="n">get_image</span><span class="p">()</span>
            <span class="n">box_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">prop</span><span class="o">.</span><span class="n">proposal_boxes</span><span class="p">),</span> <span class="n">max_vis_prop</span><span class="p">)</span>
            <span class="n">v_pred</span> <span class="o">=</span> <span class="n">Visualizer</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">v_pred</span> <span class="o">=</span> <span class="n">v_pred</span><span class="o">.</span><span class="n">overlay_instances</span><span class="p">(</span>
                <span class="n">boxes</span><span class="o">=</span><span class="n">prop</span><span class="o">.</span><span class="n">proposal_boxes</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">box_size</span><span class="p">]</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="n">prop_img</span> <span class="o">=</span> <span class="n">v_pred</span><span class="o">.</span><span class="n">get_image</span><span class="p">()</span>

            <span class="n">num_classes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">roi_heads</span><span class="o">.</span><span class="n">box_predictor</span><span class="o">.</span><span class="n">num_classes</span>
            <span class="k">if</span> <span class="n">feedbacks</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">v_feedback_gt</span> <span class="o">=</span> <span class="n">Visualizer</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="n">instance</span> <span class="o">=</span> <span class="n">feedbacks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">))</span>
                <span class="n">v_feedback_gt</span> <span class="o">=</span> <span class="n">v_feedback_gt</span><span class="o">.</span><span class="n">overlay_instances</span><span class="p">(</span>
                    <span class="n">boxes</span><span class="o">=</span><span class="n">instance</span><span class="o">.</span><span class="n">proposal_boxes</span><span class="p">[</span><span class="n">instance</span><span class="o">.</span><span class="n">gt_classes</span> <span class="o">!=</span> <span class="n">num_classes</span><span class="p">])</span>
                <span class="n">feedback_gt_img</span> <span class="o">=</span> <span class="n">v_feedback_gt</span><span class="o">.</span><span class="n">get_image</span><span class="p">()</span>

                <span class="n">v_feedback_gf</span> <span class="o">=</span> <span class="n">Visualizer</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="n">v_feedback_gf</span> <span class="o">=</span> <span class="n">v_feedback_gf</span><span class="o">.</span><span class="n">overlay_instances</span><span class="p">(</span>
                    <span class="n">boxes</span><span class="o">=</span><span class="n">instance</span><span class="o">.</span><span class="n">proposal_boxes</span><span class="p">[</span><span class="n">instance</span><span class="o">.</span><span class="n">gt_classes</span> <span class="o">==</span> <span class="n">num_classes</span><span class="p">])</span>
                <span class="n">feedback_gf_img</span> <span class="o">=</span> <span class="n">v_feedback_gf</span><span class="o">.</span><span class="n">get_image</span><span class="p">()</span>

                <span class="n">vis_img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">anno_img</span><span class="p">,</span> <span class="n">prop_img</span><span class="p">,</span> <span class="n">feedback_gt_img</span><span class="p">,</span> <span class="n">feedback_gf_img</span><span class="p">))</span>
                <span class="n">vis_img</span> <span class="o">=</span> <span class="n">vis_img</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">vis_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Top: GT; Middle: Pred; Bottom: Feedback GT, Feedback GF&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">vis_img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">anno_img</span><span class="p">,</span> <span class="n">prop_img</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">vis_img</span> <span class="o">=</span> <span class="n">vis_img</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">vis_name</span> <span class="o">=</span> <span class="s2">&quot;Left: GT bounding boxes;  Right: Predicted proposals&quot;</span>
            <span class="n">storage</span><span class="o">.</span><span class="n">put_image</span><span class="p">(</span><span class="n">vis_name</span><span class="p">,</span> <span class="n">vis_img</span><span class="p">)</span>
            <span class="k">break</span>  <span class="c1"># only visualize one image in a batch</span>

    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">batched_inputs</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span>
        <span class="n">detected_instances</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Instances</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">do_postprocess</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run inference on the given inputs.</span>

<span class="sd">        Args:</span>
<span class="sd">            batched_inputs (list[dict]): same as in :meth:`forward`</span>
<span class="sd">            detected_instances (None or list[Instances]): if not None, it</span>
<span class="sd">                contains an `Instances` object per image. The `Instances`</span>
<span class="sd">                object contains &quot;pred_boxes&quot; and &quot;pred_classes&quot; which are</span>
<span class="sd">                known boxes in the image.</span>
<span class="sd">                The inference will then skip the detection of bounding boxes,</span>
<span class="sd">                and only predict other per-ROI outputs.</span>
<span class="sd">            do_postprocess (bool): whether to apply post-processing on the outputs.</span>

<span class="sd">        Returns:</span>
<span class="sd">            When do_postprocess=True, same as in :meth:`forward`.</span>
<span class="sd">            Otherwise, a list[Instances] containing raw network outputs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span>

        <span class="n">images</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess_image</span><span class="p">(</span><span class="n">batched_inputs</span><span class="p">)</span>
        <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backbone</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">tensor</span><span class="p">)</span>
        <span class="n">proposals</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proposal_generator</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="n">results</span><span class="p">,</span> <span class="n">background_results</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">roi_heads</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">proposals</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">processed_results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">results_per_image</span><span class="p">,</span> <span class="n">background_results_per_image</span><span class="p">,</span> <span class="n">input_per_image</span><span class="p">,</span> <span class="n">image_size</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="n">results</span><span class="p">,</span> <span class="n">background_results</span><span class="p">,</span> <span class="n">batched_inputs</span><span class="p">,</span> <span class="n">images</span><span class="o">.</span><span class="n">image_sizes</span>
        <span class="p">):</span>
            <span class="n">height</span> <span class="o">=</span> <span class="n">input_per_image</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;height&quot;</span><span class="p">,</span> <span class="n">image_size</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">width</span> <span class="o">=</span> <span class="n">input_per_image</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;width&quot;</span><span class="p">,</span> <span class="n">image_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">r</span> <span class="o">=</span> <span class="n">detector_postprocess</span><span class="p">(</span><span class="n">results_per_image</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">)</span>
            <span class="n">background_r</span> <span class="o">=</span> <span class="n">detector_postprocess</span><span class="p">(</span><span class="n">background_results_per_image</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">)</span>
            <span class="n">processed_results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;instances&quot;</span><span class="p">:</span> <span class="n">r</span><span class="p">,</span> <span class="s1">&#39;background&#39;</span><span class="p">:</span> <span class="n">background_r</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">processed_results</span></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright THUML Group.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://github.com/pytorch/pytorch_sphinx_theme">PyTorch Sphinx Theme</a>.
      </div>
      <!-- <div>
        <a href="https://beian.miit.gov.cn/">京ICP备16023543号-1</a>
      </div> -->
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../../../../" src="../../../../../../_static/documentation_options.js"></script>
         <script src="../../../../../../_static/jquery.js"></script>
         <script src="../../../../../../_static/underscore.js"></script>
         <script src="../../../../../../_static/doctools.js"></script>
         <script src="../../../../../../_static/language_data.js"></script>
         <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
     

  

  <script type="text/javascript" src="../../../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(false);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <!-- <div class="col-md-4 text-center">
          <h2>Survey</h2>
          <p>Access comprehensive survey for transfer learning</p>
          <a class="with-right-arrow" href="">View Survey</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Papers</h2>
          <p>Access comprehensive paper list for transfer learning</p>
          <a class="with-right-arrow" href="https://github.com/thuml/Awesome-Transferability-in-Deep-Learning">View Paper List</a>
        </div> -->

        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive documentation for Transfer Learning Library</p>
          <a class="with-right-arrow" href="transfer.thuml.ai">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get started for Transfer Learning Library</p>
          <a class="with-right-arrow" href="http://microhhh.com/get_started/installing.html">Get Started</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Paper List</h2>
          <p>Get started for transfer learning</p>
          <a class="with-right-arrow" href="https://github.com/thuml/Awesome-Transferability-in-Deep-Learning">View Resources</a>
        </div>
      </div>
    </div>
  </div>



  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="transfer.thuml.ai" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="http://microhhh.com/get_started/installing.html">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="transfer.thuml.ai">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/elastic/">TorchElastic</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/thuml/Transfer-Learning-Library/">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>