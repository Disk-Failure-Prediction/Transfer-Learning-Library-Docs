


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>tllib.vision.models.reid.loss &mdash; Transfer Learning Library 0.0.24 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" /> -->
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" /> 

  
  <script src="../../../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
<!--      pytorch logo -->
<!--      <a class="header-logo" href="transfer.thuml.ai" aria-label="PyTorch"></a>-->

      <div class="main-menu">
        <ul>
          <!-- <li>
            <a href="">Full Survey</a>
          </li>
          <li>
            <a href="https://github.com/thuml/Awesome-Transferability-in-Deep-Learning">Paper List</a>
          </li> -->
          <li>
            <li>
              <a href="transfer.thuml.ai">Docs</a>
            </li>
            
            <li>
              <a href="https://github.com/thuml/Transfer-Learning-Library/">Github</a>
            </li>

            <li>
              <a href="https://arxiv.org/abs/2201.05867">Survey</a>
            </li>

          <li>
            <a href="https://github.com/thuml/Awesome-Transferability-in-Deep-Learning">Paper List</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Transfer Learning API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tllib/modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tllib/alignment/index.html">Feature Alignment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tllib/translation.html">Domain Translation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tllib/self_training.html">Self Training Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tllib/reweight.html">Re-weighting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tllib/normalization.html">Normalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tllib/regularization.html">Regularization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tllib/ranking.html">Ranking</a></li>
</ul>
<p class="caption"><span class="caption-text">Common API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tllib/vision/index.html">Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tllib/utils/index.html">Utilities</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../../../index.html">Module code</a> &gt;</li>
        
      <li>tllib.vision.models.reid.loss</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for tllib.vision.models.reid.loss</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Modified from https://github.com/yxgeee/MMT</span>
<span class="sd">@author: Baixu Chen</span>
<span class="sd">@contact: cbx_99_hasta@outlook.com</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>


<span class="k">def</span> <span class="nf">pairwise_euclidean_distance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute pairwise euclidean distance between two sets of features&quot;&quot;&quot;</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">dist_mat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span> <span class="o">+</span> \
               <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span><span class="o">.</span><span class="n">t</span><span class="p">()</span> \
               <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">t</span><span class="p">())</span>
    <span class="c1"># for numerical stability</span>
    <span class="n">dist_mat</span> <span class="o">=</span> <span class="n">dist_mat</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">dist_mat</span>


<span class="k">def</span> <span class="nf">hard_examples_mining</span><span class="p">(</span><span class="n">dist_mat</span><span class="p">,</span> <span class="n">identity_mat</span><span class="p">,</span> <span class="n">return_idxes</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Select hard positives and hard negatives according to `In defense of the Triplet Loss for Person</span>
<span class="sd">    Re-Identification (ICCV 2017) &lt;https://arxiv.org/pdf/1703.07737v2.pdf&gt;`_</span>

<span class="sd">    Args:</span>
<span class="sd">        dist_mat (tensor): pairwise distance matrix between two sets of features</span>
<span class="sd">        identity_mat (tensor): a matrix of shape :math:`(N, M)`. If two images :math:`P[i]` of set :math:`P` and</span>
<span class="sd">            :math:`Q[j]` of set :math:`Q` come from the same person, then :math:`identity\_mat[i, j] = 1`,</span>
<span class="sd">            otherwise :math:`identity\_mat[i, j] = 0`</span>
<span class="sd">        return_idxes (bool, optional): if True, also return indexes of hard examples. Default: False</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># the implementation here is a little tricky, dist_mat contains pairwise distance between probe image and other</span>
    <span class="c1"># images in current mini-batch. As we want to select positive examples of the same person, we add a constant</span>
    <span class="c1"># negative offset on other images before sorting. As a result, images of the **same** person will rank first.</span>
    <span class="n">sorted_dist_mat</span><span class="p">,</span> <span class="n">sorted_idxes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">dist_mat</span> <span class="o">+</span> <span class="p">(</span><span class="o">-</span><span class="mf">1e7</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">identity_mat</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                               <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">dist_ap</span> <span class="o">=</span> <span class="n">sorted_dist_mat</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">hard_positive_idxes</span> <span class="o">=</span> <span class="n">sorted_idxes</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>

    <span class="c1"># the implementation here is similar to above code, we add a constant positive offset on images of same person</span>
    <span class="c1"># before sorting. Besides, we sort in ascending order. As a result, images of **different** persons will rank first.</span>
    <span class="n">sorted_dist_mat</span><span class="p">,</span> <span class="n">sorted_idxes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">dist_mat</span> <span class="o">+</span> <span class="mf">1e7</span> <span class="o">*</span> <span class="n">identity_mat</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                               <span class="n">descending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">dist_an</span> <span class="o">=</span> <span class="n">sorted_dist_mat</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">hard_negative_idxes</span> <span class="o">=</span> <span class="n">sorted_idxes</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">return_idxes</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">dist_ap</span><span class="p">,</span> <span class="n">dist_an</span><span class="p">,</span> <span class="n">hard_positive_idxes</span><span class="p">,</span> <span class="n">hard_negative_idxes</span>
    <span class="k">return</span> <span class="n">dist_ap</span><span class="p">,</span> <span class="n">dist_an</span>


<span class="k">class</span> <span class="nc">CrossEntropyLossWithLabelSmooth</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Cross entropy loss with label smooth from `Rethinking the Inception Architecture for Computer Vision</span>
<span class="sd">    (CVPR 2016) &lt;https://arxiv.org/pdf/1512.00567.pdf&gt;`_.</span>

<span class="sd">    Given one-hot labels :math:`labels \in R^C`, where :math:`C` is the number of classes,</span>
<span class="sd">    smoothed labels are calculated as</span>

<span class="sd">    .. math::</span>
<span class="sd">        smoothed\_labels = (1 - \epsilon) \times labels + \epsilon \times \frac{1}{C}</span>

<span class="sd">    We use smoothed labels when calculating cross entropy loss and this can be helpful for preventing over-fitting.</span>

<span class="sd">    Args:</span>
<span class="sd">        num_classes (int): number of classes.</span>
<span class="sd">        epsilon (float): a float number that controls the smoothness.</span>

<span class="sd">    Inputs:</span>
<span class="sd">        - y (tensor): unnormalized classifier predictions, :math:`y`</span>
<span class="sd">        - labels (tensor): ground truth labels, :math:`labels`</span>

<span class="sd">    Shape:</span>
<span class="sd">        - y: :math:`(minibatch, C)`, where :math:`C` is the number of classes</span>
<span class="sd">        - labels: :math:`(minibatch, )`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CrossEntropyLossWithLabelSmooth</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="n">log_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">log_prob</span><span class="p">)</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span> <span class="o">*</span> <span class="n">labels</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span> <span class="n">labels</span> <span class="o">*</span> <span class="n">log_prob</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss</span>


<div class="viewcode-block" id="TripletLoss"><a class="viewcode-back" href="../../../../../tllib/vision/models.html#tllib.vision.models.reid.loss.TripletLoss">[docs]</a><span class="k">class</span> <span class="nc">TripletLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Triplet loss augmented with batch hard from `In defense of the Triplet Loss for Person Re-Identification</span>
<span class="sd">    (ICCV 2017) &lt;https://arxiv.org/pdf/1703.07737v2.pdf&gt;`_.</span>

<span class="sd">    Args:</span>
<span class="sd">        margin (float): margin of triplet loss</span>
<span class="sd">        normalize_feature (bool, optional): if True, normalize features into unit norm first before computing loss.</span>
<span class="sd">            Default: False.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">margin</span><span class="p">,</span> <span class="n">normalize_feature</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TripletLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">margin</span> <span class="o">=</span> <span class="n">margin</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalize_feature</span> <span class="o">=</span> <span class="n">normalize_feature</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">margin_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MarginRankingLoss</span><span class="p">(</span><span class="n">margin</span><span class="o">=</span><span class="n">margin</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize_feature</span><span class="p">:</span>
            <span class="c1"># equivalent to cosine similarity</span>
            <span class="n">f</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
        <span class="n">dist_mat</span> <span class="o">=</span> <span class="n">pairwise_euclidean_distance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

        <span class="n">n</span> <span class="o">=</span> <span class="n">dist_mat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">identity_mat</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">t</span><span class="p">())</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

        <span class="n">dist_ap</span><span class="p">,</span> <span class="n">dist_an</span> <span class="o">=</span> <span class="n">hard_examples_mining</span><span class="p">(</span><span class="n">dist_mat</span><span class="p">,</span> <span class="n">identity_mat</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">dist_ap</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">margin_loss</span><span class="p">(</span><span class="n">dist_an</span><span class="p">,</span> <span class="n">dist_ap</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span></div>


<span class="k">class</span> <span class="nc">TripletLossXBM</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Triplet loss augmented with batch hard from `In defense of the Triplet Loss for Person Re-Identification</span>
<span class="sd">    (ICCV 2017) &lt;https://arxiv.org/pdf/1703.07737v2.pdf&gt;`_. The only difference from triplet loss lies in that</span>
<span class="sd">    both features from current mini batch and external storage (XBM) are involved.</span>

<span class="sd">    Args:</span>
<span class="sd">        margin (float, optional): margin of triplet loss. Default: 0.3</span>
<span class="sd">        normalize_feature (bool, optional): if True, normalize features into unit norm first before computing loss.</span>
<span class="sd">            Default: False</span>

<span class="sd">    Inputs:</span>
<span class="sd">        - f (tensor): features of current mini batch, :math:`f`</span>
<span class="sd">        - labels (tensor): identity labels for current mini batch, :math:`labels`</span>
<span class="sd">        - xbm_f (tensor): features collected from XBM, :math:`xbm\_f`</span>
<span class="sd">        - xbm_labels (tensor): corresponding identity labels of xbm_f, :math:`xbm\_labels`</span>

<span class="sd">    Shape:</span>
<span class="sd">        - f: :math:`(minibatch, F)`, where :math:`F` is the feature dimension</span>
<span class="sd">        - labels: :math:`(minibatch, )`</span>
<span class="sd">        - xbm_f: :math:`(minibatch, F)`</span>
<span class="sd">        - xbm_labels: :math:`(minibatch, )`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">normalize_feature</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TripletLossXBM</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">margin</span> <span class="o">=</span> <span class="n">margin</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalize_feature</span> <span class="o">=</span> <span class="n">normalize_feature</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ranking_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MarginRankingLoss</span><span class="p">(</span><span class="n">margin</span><span class="o">=</span><span class="n">margin</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">xbm_f</span><span class="p">,</span> <span class="n">xbm_labels</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize_feature</span><span class="p">:</span>
            <span class="c1"># equivalent to cosine similarity</span>
            <span class="n">f</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
            <span class="n">xbm_f</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">xbm_f</span><span class="p">)</span>

        <span class="n">dist_mat</span> <span class="o">=</span> <span class="n">pairwise_euclidean_distance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">xbm_f</span><span class="p">)</span>

        <span class="c1"># hard examples mining</span>
        <span class="n">n</span><span class="p">,</span> <span class="n">m</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">xbm_f</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">identity_mat</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">t</span><span class="p">()</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">xbm_labels</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">dist_ap</span><span class="p">,</span> <span class="n">dist_an</span> <span class="o">=</span> <span class="n">hard_examples_mining</span><span class="p">(</span><span class="n">dist_mat</span><span class="p">,</span> <span class="n">identity_mat</span><span class="p">)</span>

        <span class="c1"># Compute ranking hinge loss</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">dist_an</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ranking_loss</span><span class="p">(</span><span class="n">dist_an</span><span class="p">,</span> <span class="n">dist_ap</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span>


<div class="viewcode-block" id="SoftTripletLoss"><a class="viewcode-back" href="../../../../../tllib/self_training.html#tllib.vision.models.reid.loss.SoftTripletLoss">[docs]</a><span class="k">class</span> <span class="nc">SoftTripletLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Soft triplet loss from `Mutual Mean-Teaching: Pseudo Label Refinery for Unsupervised</span>
<span class="sd">    Domain Adaptation on Person Re-identification (ICLR 2020) &lt;https://arxiv.org/pdf/2001.01526.pdf&gt;`_.</span>
<span class="sd">    Consider a triplet :math:`x,x_p,x_n` (anchor, positive, negative), corresponding features are :math:`f,f_p,f_n`.</span>
<span class="sd">    We optimize for a smaller distance between :math:`f` and :math:`f_p` and a larger distance</span>
<span class="sd">    between :math:`f` and :math:`f_n`. Inner product is adopted as their similarity measure, soft triplet loss is thus</span>
<span class="sd">    defined as</span>

<span class="sd">    .. math::</span>
<span class="sd">        loss = \mathcal{L}_{\text{bce}}(\frac{\text{exp}(f^Tf_p)}{\text{exp}(f^Tf_p)+\text{exp}(f^Tf_n)}, 1)</span>

<span class="sd">    where :math:`\mathcal{L}_{\text{bce}}` means binary cross entropy loss. We denote the first term in above loss function</span>
<span class="sd">    as :math:`T`. When features from another teacher network can be obtained, we can calculate :math:`T_{teacher}` as</span>
<span class="sd">    labels, resulting in the following soft version</span>

<span class="sd">    .. math::</span>
<span class="sd">        loss = \mathcal{L}_{\text{bce}}(T, T_{teacher})</span>

<span class="sd">    Args:</span>
<span class="sd">        margin (float, optional): margin of triplet loss. If None, soft labels from another network will be adopted when</span>
<span class="sd">            computing loss. Default: None.</span>
<span class="sd">        normalize_feature (bool, optional): if True, normalize features into unit norm first before computing loss.</span>
<span class="sd">            Default: False.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">normalize_feature</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SoftTripletLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">margin</span> <span class="o">=</span> <span class="n">margin</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalize_feature</span> <span class="o">=</span> <span class="n">normalize_feature</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features_1</span><span class="p">,</span> <span class="n">features_2</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize_feature</span><span class="p">:</span>
            <span class="c1"># equal to cosine similarity</span>
            <span class="n">features_1</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">features_1</span><span class="p">)</span>
            <span class="n">features_2</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">features_2</span><span class="p">)</span>

        <span class="n">dist_mat</span> <span class="o">=</span> <span class="n">pairwise_euclidean_distance</span><span class="p">(</span><span class="n">features_1</span><span class="p">,</span> <span class="n">features_1</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">dist_mat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">dist_mat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">n</span> <span class="o">=</span> <span class="n">dist_mat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">identity_mat</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">t</span><span class="p">())</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

        <span class="n">dist_ap</span><span class="p">,</span> <span class="n">dist_an</span><span class="p">,</span> <span class="n">ap_idxes</span><span class="p">,</span> <span class="n">an_idxes</span> <span class="o">=</span> <span class="n">hard_examples_mining</span><span class="p">(</span><span class="n">dist_mat</span><span class="p">,</span> <span class="n">identity_mat</span><span class="p">,</span> <span class="n">return_idxes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">dist_an</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">dist_ap</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">triple_dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">dist_ap</span><span class="p">,</span> <span class="n">dist_an</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">triple_dist</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">triple_dist</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">margin</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">margin</span> <span class="o">*</span> <span class="n">triple_dist</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">margin</span><span class="p">)</span> <span class="o">*</span> <span class="n">triple_dist</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">loss</span>

        <span class="n">dist_mat_ref</span> <span class="o">=</span> <span class="n">pairwise_euclidean_distance</span><span class="p">(</span><span class="n">features_2</span><span class="p">,</span> <span class="n">features_2</span><span class="p">)</span>
        <span class="n">dist_ap_ref</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">dist_mat_ref</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">ap_idxes</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">))[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">dist_an_ref</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">dist_mat_ref</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">an_idxes</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">))[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">triple_dist_ref</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">dist_ap_ref</span><span class="p">,</span> <span class="n">dist_an_ref</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">triple_dist_ref</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">triple_dist_ref</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span> <span class="n">triple_dist_ref</span> <span class="o">*</span> <span class="n">triple_dist</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss</span></div>


<div class="viewcode-block" id="CrossEntropyLoss"><a class="viewcode-back" href="../../../../../tllib/self_training.html#tllib.vision.models.reid.loss.CrossEntropyLoss">[docs]</a><span class="k">class</span> <span class="nc">CrossEntropyLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;We use :math:`C` to denote the number of classes, :math:`N` to denote mini-batch</span>
<span class="sd">    size, this criterion expects unnormalized predictions :math:`y\_{logits}` of shape :math:`(N, C)` and</span>
<span class="sd">    :math:`target\_{logits}` of the same shape :math:`(N, C)`. Then we first normalize them into</span>
<span class="sd">    probability distributions among classes</span>

<span class="sd">    .. math::</span>
<span class="sd">        y = \text{softmax}(y\_{logits})</span>
<span class="sd">    .. math::</span>
<span class="sd">        target = \text{softmax}(target\_{logits})</span>

<span class="sd">    Final objective is calculated as</span>

<span class="sd">    .. math::</span>
<span class="sd">        \text{loss} = \frac{1}{N} \sum_{i=1}^{N} \sum_{j=1}^C -target_i^j \times \text{log} (y_i^j)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CrossEntropyLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="n">log_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="o">*</span> <span class="n">log_prob</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss</span></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright THUML Group.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://github.com/pytorch/pytorch_sphinx_theme">PyTorch Sphinx Theme</a>.
      </div>
      <!-- <div>
        <a href="https://beian.miit.gov.cn/">京ICP备16023543号-1</a>
      </div> -->
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../../../" src="../../../../../_static/documentation_options.js"></script>
         <script src="../../../../../_static/jquery.js"></script>
         <script src="../../../../../_static/underscore.js"></script>
         <script src="../../../../../_static/doctools.js"></script>
         <script src="../../../../../_static/language_data.js"></script>
         <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
     

  

  <script type="text/javascript" src="../../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(false);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <!-- <div class="col-md-4 text-center">
          <h2>Survey</h2>
          <p>Access comprehensive survey for transfer learning</p>
          <a class="with-right-arrow" href="">View Survey</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Papers</h2>
          <p>Access comprehensive paper list for transfer learning</p>
          <a class="with-right-arrow" href="https://github.com/thuml/Awesome-Transferability-in-Deep-Learning">View Paper List</a>
        </div> -->

        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive documentation for Transfer Learning Library</p>
          <a class="with-right-arrow" href="transfer.thuml.ai">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get started for Transfer Learning Library</p>
          <a class="with-right-arrow" href="http://microhhh.com/get_started/installing.html">Get Started</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Paper List</h2>
          <p>Get started for transfer learning</p>
          <a class="with-right-arrow" href="https://github.com/thuml/Awesome-Transferability-in-Deep-Learning">View Resources</a>
        </div>
      </div>
    </div>
  </div>



  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="transfer.thuml.ai" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="http://microhhh.com/get_started/installing.html">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="transfer.thuml.ai">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/elastic/">TorchElastic</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/thuml/Transfer-Learning-Library/">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>